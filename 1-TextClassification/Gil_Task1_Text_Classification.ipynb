{"cells":[{"cell_type":"markdown","metadata":{"id":"rzQpZte7CJG7"},"source":["# Text Classification\n","## This notebook outlines the usage of NLP Feature extraction (CountVectorizer, TfidfVectorizer) in classification of text documents"]},{"cell_type":"markdown","metadata":{"id":"JDxrHGI5CJG-"},"source":["### Import all the necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"dgJSqxrtCJG_","executionInfo":{"status":"ok","timestamp":1741765448655,"user_tz":240,"elapsed":6564,"user":{"displayName":"Gil Adiao","userId":"07432047655131910658"}}},"outputs":[],"source":["from pprint import pprint\n","from time import time\n","import logging\n","\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline"]},{"cell_type":"markdown","metadata":{"id":"yXTF3Y5sCJHA"},"source":["### Choose a few categories fro the entire 20 categories"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"0YXFeXS3CJHA","executionInfo":{"status":"ok","timestamp":1741765448661,"user_tz":240,"elapsed":2,"user":{"displayName":"Gil Adiao","userId":"07432047655131910658"}}},"outputs":[],"source":["# Load some categories from the training set\n","categories = [\n","    'alt.atheism',\n","    'talk.religion.misc',\n","]"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RmaC9NtiCJHA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741765448675,"user_tz":240,"elapsed":11,"user":{"displayName":"Gil Adiao","userId":"07432047655131910658"}},"outputId":"65ea0070-d9c0-4dd2-abd7-51a23962efc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading 20 newsgroups dataset for categories:\n","['alt.atheism', 'talk.religion.misc']\n"]}],"source":["print(\"Loading 20 newsgroups dataset for categories:\")\n","print(categories)"]},{"cell_type":"markdown","metadata":{"id":"kQZrkeisCJHB"},"source":["### Fetch documents for these 2 categories"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"WWNRzFBzCJHB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741765473617,"user_tz":240,"elapsed":24940,"user":{"displayName":"Gil Adiao","userId":"07432047655131910658"}},"outputId":"3ebf2eb3-4d6e-4fc0-808a-28cae3c030a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["857 documents\n","2 categories\n","\n"]}],"source":["data = fetch_20newsgroups(subset='train', categories=categories)\n","print(f\"{len(data.filenames)} documents\")\n","print(f\"{len(data.target_names)} categories\")\n","print()"]},{"cell_type":"markdown","metadata":{"id":"JI9AZui1CJHB"},"source":["### Define a pipeline combining a text feature extractor with a simple classifier"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"9kkHsLiaCJHB","executionInfo":{"status":"ok","timestamp":1741765473619,"user_tz":240,"elapsed":3,"user":{"displayName":"Gil Adiao","userId":"07432047655131910658"}}},"outputs":[],"source":["pipeline = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('tfidf', TfidfTransformer()),\n","    ('clf', SGDClassifier(tol=1e-3)),\n","])"]},{"cell_type":"markdown","metadata":{"id":"0Fsg78uECJHC"},"source":["### Specify parameter grid\n","- 'vect__max_df': (0.5, 0.75, 1.0)\n","- 'vect__max_features': (None, 5000, 10000, 50000)\n","- 'vect__ngram_range': ((1, 1), (1, 2))\n","- 'tfidf__use_idf': (True, False)\n","- 'tfidf__norm': ('l1', 'l2')\n","- 'clf__max_iter': (20,)\n","- 'clf__alpha': (0.00001, 0.000001)\n","- 'clf__penalty': ('l2', 'elasticnet')\n","- 'clf__max_iter': (10, 50, 80)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6hoHEoqGCJHC","executionInfo":{"status":"ok","timestamp":1741765473621,"user_tz":240,"elapsed":1,"user":{"displayName":"Gil Adiao","userId":"07432047655131910658"}}},"outputs":[],"source":["parameters = {\n","    'vect__max_df': (0.5, 0.75, 1.0),\n","    'vect__max_features': (None, 5000, 10000, 50000),\n","    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n","    'tfidf__use_idf': (True, False),\n","    'tfidf__norm': ('l1', 'l2'),\n","    'clf__max_iter': (20,),\n","    'clf__alpha': (0.00001, 0.000001),\n","    'clf__penalty': ('l2', 'elasticnet'),\n","    'clf__max_iter': (10, 50, 80),\n","}"]},{"cell_type":"markdown","metadata":{"id":"moaGXbqhCJHC"},"source":["### Find the best parameters for both the feature extraction and the classifier"]},{"cell_type":"markdown","metadata":{"id":"eUHUx0GzCJHC"},"source":["### Build a GridSearch with the pipeline and parameter grid"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ZZsmpZ0dCJHC","executionInfo":{"status":"ok","timestamp":1741765473623,"user_tz":240,"elapsed":1,"user":{"displayName":"Gil Adiao","userId":"07432047655131910658"}}},"outputs":[],"source":["grid_search = GridSearchCV(pipeline, parameters, cv=5,\n","                           n_jobs=-1, verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"tj4KEzhxCJHC"},"source":["### Start the grid search"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8WVjodMdCJHC","outputId":"d8642727-7302-42e3-faec-a19e4f40c0ff"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n"]}],"source":["grid_search.fit(data.data, data.target)"]},{"cell_type":"markdown","metadata":{"id":"wo8r_A6cCJHC"},"source":["### Best Score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3R6KZYnVCJHC"},"outputs":[],"source":["print(\"Best score: %0.3f\" % grid_search.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"wU6UvPL2CJHD"},"source":["### Best Parameter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_PoAwetCJHD"},"outputs":[],"source":["print(\"Best parameters set:\")\n","best_parameters = grid_search.best_estimator_.get_params()\n","for param_name in sorted(parameters.keys()):\n","    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"]},{"cell_type":"markdown","metadata":{"id":"T5DM5DR4CJHD"},"source":["### Choose the best model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTRSOkliCJHD"},"outputs":[],"source":["# prompt: Choose the best model\n","\n","# Choose the best model based on the best parameters found by GridSearchCV\n","best_model = grid_search.best_estimator_\n","\n","# You can now use the best_model for predictions on new data\n","# For example:\n","# best_model.predict([\"This is a new document to classify.\"])\n"]},{"cell_type":"markdown","metadata":{"id":"f92SQLNHCJHD"},"source":["### Use the model to classify a piece of text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYvizy9TCJHD"},"outputs":[],"source":["# prompt: Use model to classify a piece of text\n","\n","# Use the model to classify a piece of text\n","new_text = [\"This is a new document to classify.\"]\n","predicted_category = best_model.predict(new_text)\n","print(f\"Predicted category for new text: {predicted_category}\")\n","predicted_category_name = data.target_names[predicted_category[0]]\n","print(f\"Predicted category name: {predicted_category_name}\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}