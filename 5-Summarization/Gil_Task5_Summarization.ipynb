{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gil Paolo Adiao (101590566)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "#### ASSIGNMENT: \n",
    "Take the same medium article (the one I wrote) we used for Task 1 of ML-1 and extract the text and summarize them using all the above methods and provide the best summary with a note saying why the chosen library is the best\n",
    "url = https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7\n",
    "\n",
    "#### Submit 2 files\n",
    "- (notebook) .ipynb\n",
    "- (summary) .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from beautifulsoup4) (2.4.1)\n",
      "Requirement already satisfied: sumy in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: lxml_html_clean in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from sumy) (2.31.0)\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from sumy) (0.6.2)\n",
      "Requirement already satisfied: breadability>=0.1.20 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from sumy) (0.1.20)\n",
      "Requirement already satisfied: pycountry>=18.2.23 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from sumy) (22.3.5)\n",
      "Requirement already satisfied: lxml in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from lxml_html_clean) (5.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: joblib in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: click in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: chardet in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from pycountry>=18.2.23->sumy) (65.6.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from requests>=2.7.0->sumy) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from requests>=2.7.0->sumy) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from requests>=2.7.0->sumy) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from requests>=2.7.0->sumy) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from click->nltk) (6.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from importlib-metadata->click->nltk) (4.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from importlib-metadata->click->nltk) (3.15.0)\n",
      "Requirement already satisfied: gensim==3.8.3 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from gensim==3.8.3) (0.29.14)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from gensim==3.8.3) (7.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from gensim==3.8.3) (1.17.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from gensim==3.8.3) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from gensim==3.8.3) (1.21.6)\n",
      "Requirement already satisfied: wrapt in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from smart-open>=1.8.1->gensim==3.8.3) (1.16.0)\n",
      "Requirement already satisfied: summa in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from summa) (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\gilad\\anaconda3\\envs\\ml-venv\\lib\\site-packages (from scipy>=0.19->summa) (1.21.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gilad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install requests beautifulsoup4\n",
    "!pip install sumy lxml_html_clean nltk\n",
    "!pip install gensim==3.8.3\n",
    "!pip install summa\n",
    "\n",
    "# Import common libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Import Sumy libraries\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "# Import Gensim summarization\n",
    "from gensim.summarization import summarize as gensim_summarize\n",
    "\n",
    "# Import Summa\n",
    "from summa import summarizer, keywords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subash Gandyer\n",
      "Follow\n",
      "--\n",
      "1\n",
      "Listen\n",
      "Share\n",
      "It was a cozy Sunday afternoon in the month of February 2018. I just finished my huge customary Sunday lunch spread with family and resting along. Everyone in the family was taking a quick nap for a pre-planned evening outing. Well not everyone, actually.\n",
      "My 4-year-old angel came running to me, asked me to play with her for a while. As I was lazy and not in a position to move after the big spread, I evaded the chance to play with her by telling her “Papa’s\n"
     ]
    }
   ],
   "source": [
    "# Scrape the Medium article\n",
    "url = \"https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7\"\n",
    "\n",
    "def scrape_medium_article(url):\n",
    "    # Make a request to the given URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Extract the article content\n",
    "        article = soup.find('article')\n",
    "        if article:\n",
    "            # Get all paragraphs in the article\n",
    "            paragraphs = article.find_all('p')\n",
    "            text = \"\"\n",
    "            for paragraph in paragraphs:\n",
    "                text += paragraph.get_text() + \"\\n\"\n",
    "            return text\n",
    "        else:\n",
    "            print(\"Could not find the article content.\")\n",
    "            return \"\"\n",
    "    else:\n",
    "        print(f\"Error: Unable to fetch the page. Status code: {response.status_code}\")\n",
    "        return \"\"\n",
    "\n",
    "# Scrape the Medium article\n",
    "medium_article_text = scrape_medium_article(url)\n",
    "\n",
    "# Display the first 500 characters to check the content\n",
    "print(medium_article_text[:500] if medium_article_text else \"Failed to retrieve article content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sumy\n",
    "- Luhn – Heurestic method\n",
    "- Latent Semantic Analysis\n",
    "- LexRank – Unsupervised approach inspired by algorithms PageRank and HITS\n",
    "- TextRank - Graph-based summarization technique with keyword extractions in from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use different Sumy summarizers on the Medium article and compare them\n",
    "\n",
    "# First, let's define a function to summarize using different Sumy methods\n",
    "def get_sumy_summary(text, summarizer_type, sentence_count=10):\n",
    "    # Create a parser for the text\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    \n",
    "    # Initialize the specified summarizer\n",
    "    if summarizer_type == \"luhn\":\n",
    "        summarizer = LuhnSummarizer()\n",
    "    elif summarizer_type == \"lsa\":\n",
    "        summarizer = LsaSummarizer()\n",
    "    elif summarizer_type == \"lexrank\":\n",
    "        summarizer = LexRankSummarizer()\n",
    "    elif summarizer_type == \"textrank\":\n",
    "        summarizer = TextRankSummarizer()\n",
    "    else:\n",
    "        return \"Invalid summarizer type\"\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = summarizer(parser.document, sentence_count)\n",
    "    \n",
    "    # Convert summary sentences to text\n",
    "    summary_text = \"\\n\".join(str(sentence) for sentence in summary)\n",
    "    return summary_text\n",
    "\n",
    "# Apply each summarization method\n",
    "summarizers = [\"luhn\", \"lsa\", \"lexrank\", \"textrank\"]\n",
    "summaries = {}\n",
    "\n",
    "# Apply each summarization method\n",
    "for method in summarizers:\n",
    "    summary = get_sumy_summary(medium_article_text, method, sentence_count=10)\n",
    "    summaries[method] = summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luhn Method Summary:\n",
      "--------------------------------------------------------------------------------\n",
      "“Papa, tell me what stuff means and something means.” Cannot help evade a cute curious face, I said, “I am working on Neural Network.” Before I finish the statement, “Papa, What is a Meural Metark?” I gave up my stubbornness of avoiding her.\n",
      "With a smile, I said slowly, “Its Neu — ral Net — work” She asked, “Papa, What is Meu-ral Met-ark?” At the back of my head, thoughts of me taking days to comprehend what a NN (short for Neural Network) is, how it would work, where it is used, how it is simulating our human brain’s inner workings were going through.\n",
      "“Neural Network is a collection (a network) of neurons whose job is to learn a new thing or a new place or a new process or a new concept.” It would be stupid on my part to start with a definition of Neural Network like how we used to teach adults in college.\n",
      "How you learnt it is because of Neural Network inside your brain.” Now, a neural network is a collection of neurons that keeps switching on and off based on things you see, feel, hear and think just like switching on light bulb at our home.\n",
      "For example, a face object can be seen by neurons as a circle (face) with two smaller circles (two eyes), a line (nose) and a curved line (mouth).\n",
      "Every neuron is waiting for your eyes to see something new, for your nose to smell something new, for your ears to hear something new, for your tongue to taste something new.\n",
      "When something new is heard, or smelled, or seen, or tasted, the neurons will group together to send signals and forms connections with already seen, heard, tasted or smelled neurons.\n",
      "When you see a new object, your brain will ask the neurons, ‘Hey, anybody experienced this before?’ The neurons will say, ‘Yes, I have seen this.’ Certain other neurons will say, ‘No, I have not seen this.’ The neurons that have seen this before, will group together and form logical connections from the past and gives us an object from our memory.\n",
      "Once all the features are there, the neurons will send a signal that the picture you are looking at is a lion and not a dog.\n",
      "Neurons work together in finding patterns and once a pattern is identified, it signals the brain that it is a thing, place, song, taste, smell and so on.” It was the time to test her understanding.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display the Luhn method summary\n",
    "print(\"Luhn Method Summary:\")\n",
    "print(\"-\" * 80)\n",
    "print(summaries[\"luhn\"])\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Method Summary:\n",
      "--------------------------------------------------------------------------------\n",
      "Subash Gandyer Follow -- 1 Listen Share It was a cozy Sunday afternoon in the month of February 2018.\n",
      "I just finished my huge customary Sunday lunch spread with family and resting along.\n",
      "As I was lazy and not in a position to move after the big spread, I evaded the chance to play with her by telling her “Papa’s got some work baby.\n",
      "What I was actually doing here was teaching her neural network (brain) the features of a lion like exactly how Machine Learning Engineers would train the machine to learn new features.\n",
      "I spend some time in collecting pictures of dogs and lions from Google images.\n",
      "If you’ve noticed, this is how ML people make their machines learn through Reinforcement Learning.\n",
      "For example, when I showed you a lion picture, your brain asked the neurons who had seen it before.\n",
      "Every neuron will tune itself to pick up certain features like legs, tail, face, beard, and so on.\n",
      "And I hope she will not come to me running asking “Papa, what is Meural Metark?” again.\n",
      "And I have a strong feeling; she would ask me another stunning question sooner or later.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display the Luhn method summary\n",
    "print(\"LSA Method Summary:\")\n",
    "print(\"-\" * 80)\n",
    "print(summaries[\"lsa\"])\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LexRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexRank Method Summary:\n",
      "--------------------------------------------------------------------------------\n",
      "As my daughter was very inquisitive, she asked me “Papa, what stuff?” I said, “I need to code something for my work.” She didn’t leave.\n",
      "“Neural Network is a collection (a network) of neurons whose job is to learn a new thing or a new place or a new process or a new concept.” It would be stupid on my part to start with a definition of Neural Network like how we used to teach adults in college.\n",
      "I said, “Good Job!” and asked her, “Where’s the tail, baby?” She smiled and drew a tail.\n",
      "After telling her the features of a lion, asked her “Can you draw these for me?” She happily drew almost a similar figure to that of a dog she drew before.\n",
      "Was it a dog or a lion?\n",
      "Do you know what is the difference between a lion and a dog?” She said, “Yes.” I said, “This is called Learning.\n",
      "Ultimately, the neurons in your brain tell that it is a lion and not a dog.\n",
      "This is what a neural network is and this is how it works in identifying things.\n",
      "Tanishi: That’s it.\n",
      "Me: So, for a dog, the features are face, body, legs and tail.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display the Luhn method summary:\n",
    "print(\"LexRank Method Summary:\")\n",
    "print(\"-\" * 80)\n",
    "print(summaries[\"lexrank\"])\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextRank Method Summary:\n",
      "--------------------------------------------------------------------------------\n",
      "“Papa, tell me what stuff means and something means.” Cannot help evade a cute curious face, I said, “I am working on Neural Network.” Before I finish the statement, “Papa, What is a Meural Metark?” I gave up my stubbornness of avoiding her.\n",
      "With a smile, I said slowly, “Its Neu — ral Net — work” She asked, “Papa, What is Meu-ral Met-ark?” At the back of my head, thoughts of me taking days to comprehend what a NN (short for Neural Network) is, how it would work, where it is used, how it is simulating our human brain’s inner workings were going through.\n",
      "“Neural Network is a collection (a network) of neurons whose job is to learn a new thing or a new place or a new process or a new concept.” It would be stupid on my part to start with a definition of Neural Network like how we used to teach adults in college.\n",
      "After telling her the features of a lion, asked her “Can you draw these for me?” She happily drew almost a similar figure to that of a dog she drew before.\n",
      "Do you know what is the difference between a lion and a dog?” She said, “Yes.” I said, “This is called Learning.\n",
      "How you learnt it is because of Neural Network inside your brain.” Now, a neural network is a collection of neurons that keeps switching on and off based on things you see, feel, hear and think just like switching on light bulb at our home.\n",
      "When you see a new object, your brain will ask the neurons, ‘Hey, anybody experienced this before?’ The neurons will say, ‘Yes, I have seen this.’ Certain other neurons will say, ‘No, I have not seen this.’ The neurons that have seen this before, will group together and form logical connections from the past and gives us an object from our memory.\n",
      "Once all the features are there, the neurons will send a signal that the picture you are looking at is a lion and not a dog.\n",
      "The same principle is applied for a song that you hear, a cartoon that you watch, a rhyme that you sing, an animal that you draw, a food that you taste, a flower that you smell and so on.\n",
      "Neurons work together in finding patterns and once a pattern is identified, it signals the brain that it is a thing, place, song, taste, smell and so on.” It was the time to test her understanding.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display the Luhn method summary:\n",
    "print(\"TextRank Method Summary:\")\n",
    "print(\"-\" * 80)\n",
    "print(summaries[\"textrank\"])\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Summary Lengths (character count):\n",
      "Luhn: 2238 characters\n",
      "Lsa: 1071 characters\n",
      "Lexrank: 1017 characters\n",
      "Textrank: 2189 characters\n"
     ]
    }
   ],
   "source": [
    "# Let's also check the length of each summary to compare\n",
    "print(\"\\n## Summary Lengths (character count):\")\n",
    "for method, summary in summaries.items():\n",
    "    print(f\"{method.capitalize()}: {len(summary)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim Summary with ratio=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gensim Summary with ratio=0.01:\n",
      "--------------------------------------------------------------------------------\n",
      "What I was actually doing here was teaching her neural network (brain) the features of a lion like exactly how Machine Learning Engineers would train the machine to learn new features.\n",
      "The neurons grouped together with features like face, body, legs, tail and a beard forms a lion.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gensim_summary_small = gensim_summarize(medium_article_text, ratio=0.01)\n",
    "print(\"Gensim Summary with ratio=0.01:\")\n",
    "print(\"-\" * 80)\n",
    "print(gensim_summary_small)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim Summary with ratio=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gensim Summary with ratio=0.05:\n",
      "--------------------------------------------------------------------------------\n",
      "What I was actually doing here was teaching her neural network (brain) the features of a lion like exactly how Machine Learning Engineers would train the machine to learn new features.\n",
      "After telling her the features of a lion, asked her “Can you draw these for me?” She happily drew almost a similar figure to that of a dog she drew before.\n",
      "A dog will have features like face, body, legs, and tail.\n",
      "A lion will have features like face, body, legs, tail and a beard.\n",
      "The neurons grouped together with features like face, body, legs, tail and a beard forms a lion.\n",
      "Once all the features are there, the neurons will send a signal that the picture you are looking at is a lion and not a dog.\n",
      "Every neuron will tune itself to pick up certain features like legs, tail, face, beard, and so on.\n",
      "Tanishi: Yes. Me: So, for a dog, the features are face, body, legs and tail.\n",
      "All neurons work together like your friends and identify lion and dog.\n",
      "Neural network is a group of neuron friends identifying lions and dogs.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gensim_summary_medium = gensim_summarize(medium_article_text, ratio=0.05)\n",
    "print(\"\\nGensim Summary with ratio=0.05:\")\n",
    "print(\"-\" * 80)\n",
    "print(gensim_summary_medium)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim Summary with word_count=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gensim Summary with word_count=100:\n",
      "--------------------------------------------------------------------------------\n",
      "What I was actually doing here was teaching her neural network (brain) the features of a lion like exactly how Machine Learning Engineers would train the machine to learn new features.\n",
      "After telling her the features of a lion, asked her “Can you draw these for me?” She happily drew almost a similar figure to that of a dog she drew before.\n",
      "A dog will have features like face, body, legs, and tail.\n",
      "A lion will have features like face, body, legs, tail and a beard.\n",
      "The neurons grouped together with features like face, body, legs, tail and a beard forms a lion.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gensim_summary_words = gensim_summarize(medium_article_text, word_count=100)\n",
    "print(\"\\nGensim Summary with word_count=100:\")\n",
    "print(\"-\" * 80)\n",
    "print(gensim_summary_words)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare length of summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gensim Summary Lengths:\n",
      "Ratio 0.01: 281 characters\n",
      "Ratio 0.05: 1006 characters\n",
      "Word count 100: 562 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGensim Summary Lengths:\")\n",
    "print(f\"Ratio 0.01: {len(gensim_summary_small)} characters\")\n",
    "print(f\"Ratio 0.05: {len(gensim_summary_medium)} characters\")\n",
    "print(f\"Word count 100: {len(gensim_summary_words)} characters\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summa Summary with ratio=0.01:\n",
      "--------------------------------------------------------------------------------\n",
      "What I was actually doing here was teaching her neural network (brain) the features of a lion like exactly how Machine Learning Engineers would train the machine to learn new features.\n",
      "The neurons grouped together with features like face, body, legs, tail and a beard forms a lion.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summa_summary_small = summarizer.summarize(medium_article_text, ratio=0.01)\n",
    "print(\"Summa Summary with ratio=0.01:\")\n",
    "print(\"-\" * 80)\n",
    "print(summa_summary_small)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summa Summary with ratio=0.05:\n",
      "--------------------------------------------------------------------------------\n",
      "What I was actually doing here was teaching her neural network (brain) the features of a lion like exactly how Machine Learning Engineers would train the machine to learn new features.\n",
      "After telling her the features of a lion, asked her “Can you draw these for me?” She happily drew almost a similar figure to that of a dog she drew before.\n",
      "A lion will have features like face, body, legs, tail and a beard.\n",
      "The neurons grouped together with features like face, body, legs, tail and a beard forms a lion.\n",
      "Once all the features are there, the neurons will send a signal that the picture you are looking at is a lion and not a dog.\n",
      "Ultimately, the neurons in your brain tell that it is a lion and not a dog.\n",
      "When I ask you to draw a dog, what are the features there?\n",
      "Tanishi: Yes. Me: So, for a dog, the features are face, body, legs and tail.\n",
      "All neurons work together like your friends and identify lion and dog.\n",
      "Neural network is a group of neuron friends identifying lions and dogs.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summa_summary_medium = summarizer.summarize(medium_article_text, ratio=0.05)\n",
    "print(\"Summa Summary with ratio=0.05:\")\n",
    "print(\"-\" * 80)\n",
    "print(summa_summary_medium)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summa Summary with words=100:\n",
      "--------------------------------------------------------------------------------\n",
      "What I was actually doing here was teaching her neural network (brain) the features of a lion like exactly how Machine Learning Engineers would train the machine to learn new features.\n",
      "After telling her the features of a lion, asked her “Can you draw these for me?” She happily drew almost a similar figure to that of a dog she drew before.\n",
      "The neurons grouped together with features like face, body, legs, tail and a beard forms a lion.\n",
      "Tanishi: Yes. Me: So, for a dog, the features are face, body, legs and tail.\n",
      "Neural network is a group of neuron friends identifying lions and dogs.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Word count-based summarization\n",
    "summa_summary_words = summarizer.summarize(medium_article_text, words=100)\n",
    "print(\"Summa Summary with words=100:\")\n",
    "print(\"-\" * 80)\n",
    "print(summa_summary_words)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summa Keywords (ratio=0.05):\n",
      "tanishi\n",
      "brain\n",
      "neurons\n",
      "neuron\n",
      "baby\n",
      "learning\n",
      "learn\n",
      "like\n",
      "face\n",
      "understand\n",
      "understandable\n",
      "understanding\n",
      "new\n",
      "work\n",
      "working\n",
      "workings\n",
      "works\n",
      "network\n",
      "circle\n",
      "circles\n"
     ]
    }
   ],
   "source": [
    "# Extract keywords from the text\n",
    "summa_keywords = keywords.keywords(medium_article_text, ratio=0.05)\n",
    "print(\"Summa Keywords (ratio=0.05):\")\n",
    "print(summa_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summa Summary Lengths:\n",
      "Ratio 0.01: 281 characters\n",
      "Ratio 0.05: 984 characters\n",
      "Word count 100: 586 characters\n"
     ]
    }
   ],
   "source": [
    "# Compare summary lengths\n",
    "print(\"\\nSumma Summary Lengths:\")\n",
    "print(f\"Ratio 0.01: {len(summa_summary_small)} characters\")\n",
    "print(f\"Ratio 0.05: {len(summa_summary_medium)} characters\")\n",
    "print(f\"Word count 100: {len(summa_summary_words)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Method based on contextual Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best method and write to file\n",
    "best_method = \"lexrank\"  # Based on evaluation of all methods\n",
    "summary = summaries[best_method]\n",
    "\n",
    "with open('Gil_Best_Summary.txt', 'w') as f:\n",
    "    f.write(f\"Best Summary Method: {best_method.upper()} (from Sumy)\\n\\n\")\n",
    "    f.write(summary)\n",
    "    f.write(\"\\n\\nReasoning:\")\n",
    "    f.write(\"\\n\\nWhy LexRank?\\n\")\n",
    "    f.write(\"LexRank uses graph-based centrality scoring on a similarity graph of sentences. \")\n",
    "    f.write(\"Similar to PageRank, it connects semantically similar sentences with weighted edges based on cosine similarity of TF-IDF vectors. \")\n",
    "    f.write(\"Sentences recommended by other important sentences rank higher.\")\n",
    "    f.write(\"\\n\\nWhy was it good?\\n\")\n",
    "    f.write(\"This method was selected as the best summarization approach because it effectively captures \")\n",
    "    f.write(\"the narrative flow of the original article by showing how the professor taught his daughter about \")\n",
    "    f.write(\"neural networks using simple, relatable examples. It preserves key concepts like features \")\n",
    "    f.write(\"and how neurons work together to identify patterns, while maintaining the educational value.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
